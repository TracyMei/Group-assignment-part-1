---
title: "Spotify"
subtitle: "Practical 2, Group 26"
author: "Bilgehan Altan, Márton Cserta, Tracy Mei, Jiarui Tu"
date: "`r Sys.Date()`"
output:
  html_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages, message=FALSE}
# packages used in our report
library(tidyverse)
library(readr)
library(ggplot2)
library(dplyr)
library(caret)
library(glmnet)
library(leaps)
library(ISLR)
```


```{r import, message=FALSE}
# importing the Spotify dataset
spotify <- read_csv("Spotify-2000.csv")
```
# Introduction
In the digital music era, platforms like Spotify use a variety of audio features to describe and categorize songs, ranging from Energy and Danceability to Length (Duration). Understanding how these features relate to a song’s Popularity can provide valuable insights for both artists and music streaming services.

Preliminary exploratory data analysis revealed potential associations: songs with higher Energy and Danceability tend to be more popular, while longer songs may receive fewer plays. These observations lead us to the central research question:

"How do audio features such as Energy, Danceability, and Length influence the Popularity of songs on Spotify?"

To address this question, we employ both visual exploration, and use best subset selection and a Lasso regression model to determine which features have an impact on popularity. After selecting the best model, we explore the significance and direction of each feature’s impact on popularity. By doing so, we aim to uncover which characteristics most strongly predict a song’s success on the platform.

## Data

```{r Viewdata}
# Inspecting our dataset
head(spotify, 10)
summary(spotify)
```

The Spotify dataset consists of 1994 observations (songs), containing song attributes and popularity (ranging from 11 to 100).

```{r renaming variables}
# renaming variables to avoid errors with spaces
spotify <- spotify %>%
  mutate(BPM = `Beats Per Minute (BPM)`, .keep = "unused") %>%
  mutate(Length = `Length (Duration)`, .keep = "unused") %>%
  mutate(Loudness = `Loudness (dB)`, .keep = "unused")
```

# Exploratory graphs

```{r Graph1}
ggplot(spotify, aes(x = Energy, y = Danceability))+
  geom_col()
ggplot(spotify, aes(x = Energy, y = Popularity)) +
  geom_point(alpha = 0.6) +
  geom_smooth (method= 'lm', se = FALSE, color = "blue") +
  labs(title = "Does Higher Energy Lead to More Popular Songs?",
       x = "Energy",
       y = "Popularity") +
  theme_minimal()
#this one is comparing Energy and Popularity. so as we can see, popularity increases as energy level increase.
```

This graph shows the relationship between a song's Energy and its corresponding Danceability frequency. It can be seen that most of the songs have Energy values between 30 and 80, with a particular peak around 70, suggesting that songs with medium to high Energy levels are more common and may be more danceable. As Energy increases, the frequency of Danceability also increases, suggesting that there may be a positive correlation between the two. This finding provides a preliminary basis for further research on whether Energy and Danceability can significantly predict song popularity.


```{r Graph2}
ggplot(spotify, aes(x = Danceability, y = Popularity)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  labs(title = "Does Danceability Affect Song Popularity?",
       x = "Danceability", y = "Popularity") +
  theme_minimal()
#This one compares danceability and popularity. it also show us same relationship with energy
```

As can be seen from the graph, there is a positive correlation between a song's Energy and Popularity, i.e. songs with higher Energy may be slightly more popular overall.



```{r Graph3}
ggplot(spotify, aes(x = Energy, y = Danceability)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "orange") +
  labs(title = "Relationship Between Energy and Danceability",
       x = "Energy", y = "Danceability") +
  theme_minimal()
#following code explains the relationship between danceability and energy. there is also a positive relation between them which can be further analysed.
```

As can be seen from the graph, there is a clear positive correlation between Energy and Danceability of a song. That is, songs with higher Energy are more likely to have higher Danceability. This trend is verified by the regression line, although there is still some degree of dispersion in the data points. This finding supports the hypothesis in the previous exploratory analyses that Energy may indirectly further influence song popularity by increasing Danceability.


```{r Graph4}
spotify$Length <- as.numeric(spotify$`Length`)

spotify %>%
  filter(`Length` < 1000) %>%
  ggplot(aes(x = `Length`, y = Popularity)) +
    geom_point(alpha = 0.6) +
    geom_smooth(method = "lm", se = FALSE, color = "purple") +
    labs(title = "Does Song Length Impact Popularity?",
         x = "Song Length (sec)", y = "Popularity") +
    theme_minimal()
#this one also shows that as song length decrease, popularity increase but we need some tests i think that may not be so valid.
```

The graph shows a slight negative correlation between song length and popularity. That is, shorter songs are more likely to achieve higher popularity overall. This trend is validated by the regression line, which, despite the wide scatter distribution, still shows that longer songs are slightly less popular on the Spotify platform.

```{r Graph5}
ggplot(spotify) +
  geom_smooth(aes(x = Popularity, y = Energy,       color = "Energy"),       method = "lm", se = FALSE) +
  geom_smooth(aes(x = Popularity, y = Danceability, color = "Danceability"), method = "lm", se = FALSE) +
  geom_smooth(aes(x = Popularity, y = `Length`,      color = "Length"),       method = "lm", se = FALSE) +
  scale_color_manual("Feature",
                     values = c("Energy"="goldenrod",
                                "Danceability"="tomato",
                                "Length"="steelblue")) +
  labs(title = "Feature vs Popularity Trends",
       x     = "Popularity",
       y     = "Feature value") +
  theme_minimal()
#everything in one graph. hope it helps. it took like 1 hour to me lol..
```

This graph clearly shows the trend relationship between three audio characteristics and song popularity: Danceability and Energy are positively correlated with popularity, while Length is negatively correlated with popularity. That is, more popular songs tend to be more rhythmic and energetic, but shorter in length.

Add distribution graphs and descriptions.

# Research question

Based on the exploratory data analysis, we observe potential relationships between audio features such as Energy, Danceability, and Length (Duration) with the Popularity of songs on Spotify. The graphs suggest that higher Energy and Danceability may be associated with increased Popularity, while longer song Length might have a negative effect. Therefore, our research question is:

**"How do audio features such as Energy, Danceability, and Length influence the Popularity of songs on Spotify?"**

We will use linear regression to model this relationship and determine which features are the most significant predictors of a song's popularity.


# Linear Model

## Data Split

We split the data into training (70%), validation (15%), and test (15%) sets to ensure proper model training, selection, and evaluation.

```{r Data Split}
# Set seed for reproducibility
set.seed(123)

# Split data into 70% training, 15% validation, and 15% test
trainIndex <- createDataPartition(spotify$Popularity, p = 0.7, list = FALSE)
train_data <- spotify[trainIndex, ]
temp_data <- spotify[-trainIndex, ]

valIndex <- createDataPartition(temp_data$Popularity, p = 0.5, list = FALSE)
val_data <- temp_data[valIndex, ]
test_data <- temp_data[-valIndex, ]
```


## Model selection

We used two methods for model selection: Lasso regression and best subset selection to identify the best predictors of Popularity.

### Lasso Regression

Lasso regression was performed to select the most important features by shrinking less important coefficients to zero.

```{r Lasso Regression}
# Prepare data for glmnet
X_train <- model.matrix(Popularity ~ Energy + Danceability + Length, data = train_data)[, -1]
y_train <- train_data$Popularity

# Fit Lasso model
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1)

# Best lambda
best_lambda <- lasso_model$lambda.min

# Coefficients
coef(lasso_model, s = best_lambda)
```
### Best Subset Selection

```{r lm_mse function}
#creating a function that calculates the mses
lm_mse <- function(formula, train_data, valid_data) {
  y_name <- as.character(formula)[2]
  y_true <- valid_data[[y_name]]
  
  lm_fit <- lm(formula, train_data)
  y_pred <- predict(lm_fit, newdata = valid_data)
  
  mean((y_true - y_pred)^2)
}
```

```{r formula generating}
# function for generating all formulas for given number of predictors
generate_formulas <- function(p, x_vars, y_var) {
  # Input checking
  if (p %% 1 != 0)           stop("Input an integer n")
  if (p > length(x_vars))    stop("p should be smaller than number of vars")
  if (!is.character(x_vars)) stop("x_vars should be a character vector")
  if (!is.character(y_var))  stop("y_vars should be character type")

  apply(combn(x_vars, p), 2, function(vars) {
    paste0(y_var, " ~ ", paste(vars, collapse = " + "))
  })
}
```


```{r predictors}
# Selecting relevant (numeric) predictors
predictor_vars <- spotify %>%
  select(-Index, -Title, -Artist, -`Top Genre`, -Year, -Popularity) %>%
  colnames()
predictor_vars
```

```{r Best subset}
best_preds <- c()
best_mses <- c()

# repeating for 1 to 9 predictors
for (p in 1:9) {
  # generating formulas
  formulas <- generate_formulas(p = p, x_vars = predictor_vars, y_var = "Popularity")
  
  # calculating the mses for all models with p predictors
  mses <- rep(0, length(formulas))
  for (i in 1:length(formulas)){
    mses[i] <- lm_mse(as.formula(formulas[i]), train_data, val_data)
  }
  
  # selecting the best model for p preddictors
  best_preds[p] <- formulas[which.min(mses)]
  best_mses[p] <- min(mses)
}

# selecting the best model and its mse from the best models
best_model <- best_preds[which.min(best_mses)]
best_mse <- min(best_mses)
```

## Model evaluation

We evaluated both models on the validation set using Mean Squared Error (MSE) to determine which performs better.

```{r mse function}
mse <- function(y_true, y_pred) {
  mean((y_true - y_pred)^2)
}
```



```{r Model evaluation}
# Predict on validation set using Lasso
X_val <- model.matrix(Popularity ~ Energy + Danceability + Length, data = val_data)[, -1]
lasso_pred <- predict(lasso_model, s = best_lambda, newx = X_val)

# Calculate MSE for Lasso
lasso_mse <- mean((val_data$Popularity - lasso_pred)^2)

# Calculating the coefficients of the best model from Best Subset

lm_best_subset <- lm(best_model, train_data)

# Calculating Best Subset MSE based on test data
y_pred <- predict(lm_best_subset, newdata = test_data)
y_true <- test_data$Popularity
test_mse <- mse(y_true, y_pred)

# Compare MSE
print(paste("Lasso MSE:", round(lasso_mse, 2)))
print(paste("Best Subset MSE:", round(test_mse, 2)))
```

- Lasso Model: The MSE on the validation set was 209.28.
- Best Subset Model: Using the best subset selection, the MSE was 173.25.

The Lasso model achieved a slightly lower MSE (209.28 vs. 209.75), indicating marginally better predictive performance on the validation set. Although the difference is small, we selected the Lasso model for final evaluation due to its lower MSE.

# Results

Include the chosen regression summary, test MSE, and interpret results.

The final model selected was the **Lasso regression model**, incorporating Energy, Danceability, and Length as predictors of Popularity. This model was chosen due to its slightly lower validation Mean Squared Error (MSE) of 209.28 compared to the Best Subset model’s 209.75, indicating marginally better predictive performance.

## Final Model Evaluation
To evaluate the model’s performance on unseen data, the Lasso model was tested on the test set.

```{r Test Evaluation}
# Prepare test data for prediction
X_test <- model.matrix(Popularity ~ Energy + Danceability + Length, data = test_data)[, -1]

# Predict on test set using the Lasso model
test_pred <- predict(lasso_model, s = best_lambda, newx = X_test)

# Calculate test MSE
test_mse <- mean((test_data$Popularity - test_pred)^2)

# Output test MSE
print(paste("Test MSE:", round(test_mse, 2)))
```

The test MSE of 178.07 reflects the model’s average squared prediction error on new data, offering insight into its generalization capability.

## Model Summary

The coefficients of the Lasso regression model are:

- Intercept: 51.74
- Energy: 0.0546
- Danceability: 0.1290
- Length: -0.0089

These coefficients indicate:

- **Danceability** has the strongest positive effect, increasing Popularity by 0.1290 per unit, holding other variables constant.
- **Energy** has the strongest positive effect, increasing Popularity by 0.1290 per unit, holding other variables constant.
- **Length** has a minimal negative effect, reducing Popularity by 0.0089 per second.

The negligible coefficient for Length suggests its limited impact, while Danceability stands out as the most significant predictor.

## Interpretation

The results align with the exploratory analysis, confirming that higher **Danceability** and **Energy** are associated with greater Popularity, while **Length** has a slight negative influence. The test MSE is 178.07, indicating that the model has some predictive power, but the variance of Popularity (e.g. 500) suggests that there may be unmodeled factors, such as genre or artist popularity. Music platforms can use these insights to optimize recommendation algorithms and prioritize songs with high Danceability.

# Conclusion
Overall, the findings suggest that music platforms can prioritise works with higher danceability and energy in their recommendation algorithms, while music creators who wish to increase the popularity of their works can pay more attention to the rhythmic and dynamic qualities of their melodies, and keep the length of their songs moderate in order to adapt to the listening preferences of current users.
Although this study reveals the effects of Danceability, Energy and Length on song popularity, there are some limitations. Firstly, the model only incorporates the three audio features and does not take into account other variables such as artist popularity, music genre, and lyrics content that may significantly affect popularity. Second, the popularity metrics are based on Spotify's internal algorithms, which are calculated in an opaque way and may be affected by changes in the platform's rules. Finally, the Lasso regression is a linear model, which makes it difficult to capture non-linear relationships or complex interaction effects between variables. Future studies may consider introducing more influencing factors and adopting non-linear machine learning methods (e.g., random forests or neural networks) to enhance the predictive ability of the model; at the same time, it may also be extended to other streaming platforms for comparative analyses or to explore the dynamic evolution of popularity in combination with the temporal dimension, so as to understand the mechanism of music popularity in a more comprehensive way.
In summary, this study provides a preliminary quantitative basis for understanding the audio feature basis of song popularity, and the results are of some guiding significance for the optimisation of music recommendation systems as well as creators' creative strategies, but there is still room for further expansion and deepening.

# Contributions

* Tujiarui: Conducting data visualization analysis and writing the Introduction and Conclusion. Summarizing key insights, limitations, and future directions in the report.
* Marton: Selecting best model through best subset. Formatting and 

AI statement:

