---
title: "Spotify"
subtitle: "Practical 2, Group 26"
author: "Bilgehan Altan, Márton Cserta, Tracy Mei, Jiarui Tu"
date: "`r Sys.Date()`"
output:
  html_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages, message=FALSE}
# packages used in our report
library(tidyverse)
library(readr)
library(ggplot2)
library(dplyr)
library(caret)
library(glmnet)
library(leaps)
library(ISLR)
```


```{r import, message=FALSE}
# importing the Spotify dataset
spotify <- read_csv("Spotify-2000.csv")
```
# Introduction
In the digital music era, platforms like Spotify use a variety of audio features to describe and categorize songs, ranging from Energy and Danceability to Length (Duration). Understanding how these features relate to a song’s Popularity can provide valuable insights for both artists and music streaming services.

Preliminary exploratory data analysis revealed potential associations: songs with higher Energy and Danceability tend to be more popular, while longer songs may receive fewer plays. These observations lead us to the central research question:

"How do audio features such as Energy, Danceability, and Length influence the Popularity of songs on Spotify?"

To address this question, we employ both visual exploration, and use best subset selection and a Lasso regression model to determine which features have an impact on popularity. After selecting the best model, we explore the significance and direction of each feature’s impact on popularity. By doing so, we aim to uncover which characteristics most strongly predict a song’s success on the platform.

## Data

```{r Viewdata}
# Inspecting our dataset
head(spotify, 10)
summary(spotify)
```

The Spotify dataset consists of 1994 observations (songs), containing song attributes and popularity (ranging from 11 to 100).

```{r renaming variables}
# renaming variables to avoid errors with spaces
spotify <- spotify %>%
  mutate(BPM = `Beats Per Minute (BPM)`, .keep = "unused") %>%
  mutate(Length = `Length (Duration)`, .keep = "unused") %>%
  mutate(Loudness = `Loudness (dB)`, .keep = "unused")
```

# Exploratory graphs

```{r Graph1}
ggplot(spotify, aes(x = Energy, y = Danceability))+
  geom_col()
ggplot(spotify, aes(x = Energy, y = Popularity)) +
  geom_point(alpha = 0.6) +
  geom_smooth (method= 'lm', se = FALSE, color = "blue") +
  labs(title = "Does Higher Energy Lead to More Popular Songs?",
       x = "Energy",
       y = "Popularity") +
  theme_minimal()
#this one is comparing Energy and Popularity. so as we can see, popularity increases as energy level increase.
```

This graph shows the relationship between a song's Energy and its corresponding Danceability frequency. It can be seen that most of the songs have Energy values between 30 and 80, with a particular peak around 70, suggesting that songs with medium to high Energy levels are more common and may be more danceable. As Energy increases, the frequency of Danceability also increases, suggesting that there may be a positive correlation between the two. This finding provides a preliminary basis for further research on whether Energy and Danceability can significantly predict song popularity.


```{r Graph2}
ggplot(spotify, aes(x = Danceability, y = Popularity)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  labs(title = "Does Danceability Affect Song Popularity?",
       x = "Danceability", y = "Popularity") +
  theme_minimal()
#This one compares danceability and popularity. it also show us same relationship with energy
```

As can be seen from the graph, there is a positive correlation between a song's Energy and Popularity, i.e. songs with higher Energy may be slightly more popular overall.



```{r Graph3}
ggplot(spotify, aes(x = Energy, y = Danceability)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "orange") +
  labs(title = "Relationship Between Energy and Danceability",
       x = "Energy", y = "Danceability") +
  theme_minimal()
#following code explains the relationship between danceability and energy. there is also a positive relation between them which can be further analysed.
```

As can be seen from the graph, there is a clear positive correlation between Energy and Danceability of a song. That is, songs with higher Energy are more likely to have higher Danceability. This trend is verified by the regression line, although there is still some degree of dispersion in the data points. This finding supports the hypothesis in the previous exploratory analyses that Energy may indirectly further influence song popularity by increasing Danceability.


```{r Graph4}
spotify$Length <- as.numeric(spotify$`Length`)

spotify %>%
  filter(`Length` < 1000) %>%
  ggplot(aes(x = `Length`, y = Popularity)) +
    geom_point(alpha = 0.6) +
    geom_smooth(method = "lm", se = FALSE, color = "purple") +
    labs(title = "Does Song Length Impact Popularity?",
         x = "Song Length (sec)", y = "Popularity") +
    theme_minimal()
#this one also shows that as song length decrease, popularity increase but we need some tests i think that may not be so valid.
```

The graph shows a slight negative correlation between song length and popularity. That is, shorter songs are more likely to achieve higher popularity overall. This trend is validated by the regression line, which, despite the wide scatter distribution, still shows that longer songs are slightly less popular on the Spotify platform.

```{r Graph5}
ggplot(spotify) +
  geom_smooth(aes(x = Popularity, y = Energy,       color = "Energy"),       method = "lm", se = FALSE) +
  geom_smooth(aes(x = Popularity, y = Danceability, color = "Danceability"), method = "lm", se = FALSE) +
  geom_smooth(aes(x = Popularity, y = `Length`,      color = "Length"),       method = "lm", se = FALSE) +
  scale_color_manual("Feature",
                     values = c("Energy"="goldenrod",
                                "Danceability"="tomato",
                                "Length"="steelblue")) +
  labs(title = "Feature vs Popularity Trends",
       x     = "Popularity",
       y     = "Feature value") +
  theme_minimal()
#everything in one graph. hope it helps. it took like 1 hour to me lol..
```

This graph clearly shows the trend relationship between three audio characteristics and song popularity: Danceability and Energy are positively correlated with popularity, while Length is negatively correlated with popularity. That is, more popular songs tend to be more rhythmic and energetic, but shorter in length.

Add distribution graphs and descriptions.

# Research question

Based on the exploratory data analysis, we observe potential relationships between audio features such as Energy, Danceability, and Length (Duration) with the Popularity of songs on Spotify. The graphs suggest that higher Energy and Danceability may be associated with increased Popularity, while longer song Length might have a negative effect. Therefore, our research question is:

**"How do audio features such as Energy, Danceability, and Length influence the Popularity of songs on Spotify?"**

We will use linear regression to model this relationship and determine which features are the most significant predictors of a song's popularity.


# Linear Model

## Data Split

We split the data into training (70%), validation (15%), and test (15%) sets to ensure proper model training, selection, and evaluation.

```{r Data Split}
# Set seed for reproducibility
set.seed(123)

# Split data into 70% training, 15% validation, and 15% test
trainIndex <- createDataPartition(spotify$Popularity, p = 0.7, list = FALSE)
train_data <- spotify[trainIndex, ]
temp_data <- spotify[-trainIndex, ]

valIndex <- createDataPartition(temp_data$Popularity, p = 0.5, list = FALSE)
val_data <- temp_data[valIndex, ]
test_data <- temp_data[-valIndex, ]
```


## Model selection

We used two methods for model selection: Lasso regression and best subset selection to identify the best predictors of Popularity.

### Lasso Regression

Lasso regression was performed to select important features by shrinking less relevant coefficients to zero, using all nine predictors to ensure comprehensive feature selection.

```{r Lasso Regression}
# Define predictors
predictors <- c("BPM", "Energy", "Danceability", "Loudness", "Liveness", 
                "Valence", "Length", "Acousticness", "Speechiness")

# Prepare model matrices
X_train <- model.matrix(Popularity ~ ., data = train_data[, c("Popularity", predictors)])[ , -1]
y_train <- train_data$Popularity

X_val <- model.matrix(Popularity ~ ., data = val_data[, c("Popularity", predictors)])[ , -1]
y_val <- val_data$Popularity


# Fit Lasso with cross-validation
set.seed(123)  # for reproducibility
lasso_cv <- cv.glmnet(X_train, y_train, alpha = 1)

# Optimal lambda
lambda_opt <- lasso_cv$lambda.min
cat("Optimal lambda selected by CV:", round(lambda_opt, 4), "\n")

# Coefficient extraction
lasso_coef <- coef(lasso_cv, s = lambda_opt)
coef_df <- data.frame(
  Feature = rownames(lasso_coef),
  Coefficient = as.vector(lasso_coef)
) %>%
  filter(Coefficient != 0 & Feature != "(Intercept)")

cat("Selected predictors by Lasso:\n")
print(coef_df)

# Plot cross-validation curve
plot(lasso_cv)
title("Lasso Cross-Validation Curve", line = 2.5)
```

Using cross-validation, the optimal regularization parameter was found to be λ = 0.0264, which balances model complexity and predictive performance.

At this optimal λ, the model retained all nine predictors, indicating that each variable contributes meaningfully to the prediction of popularity, although to varying degrees.

The largest coefficients (in absolute value) were associated with:

- Loudness (+0.769): Strongest positive influence, suggesting louder songs tend to be more popular.

- Speechiness (+0.311): Positively related to popularity, potentially reflecting trends in genres with more spoken words (e.g., rap).

- Liveness (−0.126): Negatively associated with popularity, indicating that tracks with a more live performance feel might be less favored by listeners.

Other predictors such as Danceability, Valence, and Energy also contributed with moderate coefficients, while variables like BPM, Length, and Acousticness had relatively small effects.

### Best Subset Selection

```{r lm_mse function}
#creating a function that calculates the mses
lm_mse <- function(formula, train_data, valid_data) {
  y_name <- all.vars(formula)[1]
  y_true <- valid_data[[y_name]]
  
  lm_fit <- lm(formula, train_data)
  y_pred <- predict(lm_fit, newdata = valid_data)
  
  mean((y_true - y_pred)^2)
}
```

```{r formula generating}
# function for generating all formulas for given number of predictors
generate_formulas <- function(p, x_vars, y_var) {
  # Input checking
  if (p %% 1 != 0)           stop("Input an integer n")
  if (p > length(x_vars))    stop("p should be smaller than number of vars")
  if (!is.character(x_vars)) stop("x_vars should be a character vector")
  if (!is.character(y_var))  stop("y_vars should be character type")

  apply(combn(x_vars, p), 2, function(vars) {
    paste0(y_var, " ~ ", paste(vars, collapse = " + "))
  })
}
```


```{r predictors}
# Selecting relevant (numeric) predictors
predictor_vars <- spotify %>%
  select(-Index, -Title, -Artist, -`Top Genre`, -Year, -Popularity) %>%
  colnames()
predictor_vars
```

```{r Best subset}
best_preds <- c()
best_mses <- c()

# Create a dataframe to store results for readability
results_df <- data.frame(
  Num_Predictors = integer(),
  Formula = character(),
  MSE = double(),
  stringsAsFactors = FALSE
)

# repeating for 1 to 9 predictors
for (p in 1:9) {
  # generating formulas
  formulas <- generate_formulas(p = p, x_vars = predictor_vars, y_var = "Popularity")
  
  # calculating the mses for all models with p predictors
  mses <- rep(0, length(formulas))
  for (i in 1:length(formulas)){
    mses[i] <- lm_mse(as.formula(formulas[i]), train_data, val_data)
  }
  
  # selecting the best model for p preddictors
  best_preds[p] <- formulas[which.min(mses)]
  best_mses[p] <- min(mses)
}

# selecting the best model and its mse from the best models
best_model <- best_preds[which.min(best_mses)]
best_mse <- min(best_mses)
```

## Model evaluation

We evaluated both models on the validation set using Mean Squared Error (MSE) to determine which performs better.

```{r MSE function}
mse <- function(y_true, y_pred) {
  mean((y_true - y_pred)^2)
}
```

```{r Model evaluation}
set.seed(123)

# --- Lasso Regression Model Evaluation ---

# Predict Popularity on validation data using the Lasso model with optimal lambda
y_val_pred_lasso <- predict(lasso_cv, s = lambda_opt, newx = X_val)

# Calculate MSE for Lasso predictions on validation set
mse_lasso <- mse(y_val, y_val_pred_lasso)
cat("Validation MSE for Lasso regression:", round(mse_lasso, 4), "\n")

# --- Best Subset Selection Model Evaluation ---

# Fit the best subset selection model (best_model formula) on training data
best_lm <- lm(as.formula(best_model), data = train_data)

# Predict Popularity on validation data using best subset model
y_val_pred_best <- predict(best_lm, newdata = val_data)

# Calculate MSE for best subset model predictions on validation set
mse_best <- mse(val_data$Popularity, y_val_pred_best)
cat("Validation MSE for Best Subset Selection:", round(mse_best, 4), "\n")

# --- Summary Table ---

# Create a summary data frame for easy comparison
mse_summary <- data.frame(
  Model = c("Lasso Regression", "Best Subset Selection"),
  Validation_MSE = c(mse_lasso, mse_best)
)

print(mse_summary)
```


- Lasso Model: The MSE on the validation set was 203.63.
- Best Subset Model: Using the best subset selection, the MSE was 198.67.

The Best Subset Model achieved a slightly lower MSE (198.67 vs. 203.63), indicating marginally better predictive performance on the validation set. Although the difference is small, we selected the Best Subset Model for final evaluation due to its lower MSE.

# Results

Include the chosen regression summary, test MSE, and interpret results.

The final model selected was the **Best Subset Model**, incorporating Energy, Danceability, and Liveness as predictors of Popularity. This model was chosen due to its slightly lower validation Mean Squared Error (MSE) of 198.67 compared to the Best Subset model’s 203.63, indicating marginally better predictive performance.

## Final Model Evaluation
To evaluate the model’s performance on unseen data, the Best Subset Model was tested on the test set.

```{r Test Evaluation}
# Define predictor variables used in the Best Subset Selection model
predictor_vars <- c("Energy", "Danceability", "Liveness", "Valence", 
                    "Acousticness", "Speechiness", "BPM", "Length", "Loudness")

# Prepare test set matrix for prediction (remove intercept column if present)
X_test <- model.matrix(~ ., data = test_data[, predictor_vars])[ , -1]
y_test <- test_data$Popularity

# Predict using the Best Subset Selection model
y_test_pred <- predict(best_lm, newdata = test_data[, predictor_vars])

# Calculate Mean Squared Error on the test set
mse_test <- mean((y_test - y_test_pred)^2)

# Output the result
cat("Test set MSE for Best Subset Selection model:", round(mse_test, 4), "\n")
```

The test MSE of 173.25 reflects the model’s average squared prediction error on new data, offering insight into its generalization capability.

## Model Summary


## Interpretation

The results align with the exploratory analysis, confirming that higher **Danceability** and **Energy** are associated with greater Popularity, while **Length** has a slight negative influence. The test MSE is 178.07, indicating that the model has some predictive power, but the variance of Popularity (e.g. 500) suggests that there may be unmodeled factors, such as genre or artist popularity. Music platforms can use these insights to optimize recommendation algorithms and prioritize songs with high Danceability.

# Conclusion
Overall, the findings suggest that music platforms can prioritise works with higher danceability and energy in their recommendation algorithms, while music creators who wish to increase the popularity of their works can pay more attention to the rhythmic and dynamic qualities of their melodies, and keep the length of their songs moderate in order to adapt to the listening preferences of current users.
Although this study reveals the effects of Danceability, Energy and Length on song popularity, there are some limitations. Firstly, the model only incorporates the three audio features and does not take into account other variables such as artist popularity, music genre, and lyrics content that may significantly affect popularity. Second, the popularity metrics are based on Spotify's internal algorithms, which are calculated in an opaque way and may be affected by changes in the platform's rules. Finally, the Lasso regression is a linear model, which makes it difficult to capture non-linear relationships or complex interaction effects between variables. Future studies may consider introducing more influencing factors and adopting non-linear machine learning methods (e.g., random forests or neural networks) to enhance the predictive ability of the model; at the same time, it may also be extended to other streaming platforms for comparative analyses or to explore the dynamic evolution of popularity in combination with the temporal dimension, so as to understand the mechanism of music popularity in a more comprehensive way.
In summary, this study provides a preliminary quantitative basis for understanding the audio feature basis of song popularity, and the results are of some guiding significance for the optimisation of music recommendation systems as well as creators' creative strategies, but there is still room for further expansion and deepening.

# Contributions

- Tujiarui: Conducting data visualization analysis and writing the Introduction and Conclusion. Summarizing key insights, limitations, and future directions in the report.
- Marton: Selecting best model through best subset. Formatting and 
- Tracy: Generate one research question using linear regression line. Using lasso regression and Best Subset Selection, and Model evaluation.

AI statement:

